{
 "cells": [
  {
   "cell_type": "markdown",
   "source": [
    "# Jupyter notebook to compute metrics for performance comparison\n",
    "## importing packages and building dataset path"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "dd7b61497a51eb85"
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Setting up [LPIPS] perceptual loss: trunk [alex], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\filip\\.conda\\envs\\imageCompressionAI\\lib\\site-packages\\torchvision\\models\\_utils.py:208: UserWarning: The parameter 'pretrained' is deprecated since 0.13 and may be removed in the future, please use 'weights' instead.\n",
      "  warnings.warn(\n",
      "C:\\Users\\filip\\.conda\\envs\\imageCompressionAI\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=AlexNet_Weights.IMAGENET1K_V1`. You can also use `weights=AlexNet_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: C:\\Users\\filip\\.conda\\envs\\imageCompressionAI\\lib\\site-packages\\lpips\\weights\\v0.1\\alex.pth\n",
      "Setting up [LPIPS] perceptual loss: trunk [vgg], v[0.1], spatial [off]\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\filip\\.conda\\envs\\imageCompressionAI\\lib\\site-packages\\torchvision\\models\\_utils.py:223: UserWarning: Arguments other than a weight enum or `None` for 'weights' are deprecated since 0.13 and may be removed in the future. The current behavior is equivalent to passing `weights=VGG16_Weights.IMAGENET1K_V1`. You can also use `weights=VGG16_Weights.DEFAULT` to get the most up-to-date weights.\n",
      "  warnings.warn(msg)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading model from: C:\\Users\\filip\\.conda\\envs\\imageCompressionAI\\lib\\site-packages\\lpips\\weights\\v0.1\\vgg.pth\n",
      "C:\\Users\\filip\\DataspellProjects\\ImageCompressionAI\n",
      "Reference source:  C:\\Users\\filip\\DataspellProjects\\ImageCompressionAI\\IMAGES\\PNG_IMAGES\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import lpips\n",
    "import numpy\n",
    "import glob\n",
    "import torch\n",
    "from skimage import metrics\n",
    "from torchvision import transforms\n",
    "from pytorch_msssim import ms_ssim\n",
    "from PIL import Image\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "\n",
    "loss_fn_alex = lpips.LPIPS(net='alex')\n",
    "loss_fn_vgg = lpips.LPIPS(net='vgg')\n",
    "\n",
    "current_path = Path('.').resolve()\n",
    "print(str(current_path))\n",
    "\n",
    "reference_path = str(current_path)+'/IMAGES/PNG_IMAGES'\n",
    "print(\"Reference source: \",reference_path)"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T00:01:57.399355300Z",
     "start_time": "2023-10-24T00:01:52.362481400Z"
    }
   },
   "id": "90e2a20ec9c178b5"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Preparing vector of folders to compare"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "6be3f8150a66a3ea"
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "outputs": [],
   "source": [
    "datasets = {\n",
    "    'JPEG':'/IMAGES/JPEG_IMAGES'\n",
    "}\n",
    "unused = {\n",
    "    'JPEG2000':'/IMAGES/JPEG2000_IMAGES',\n",
    "    'BPG':'/IMAGES/BPG_IMAGES',\n",
    "    'VVC':'/IMAGES/VVC_IMAGES',\n",
    "    'mbt2018_1':'/IMAGES/NET/mbt2018_1',\n",
    "    'mbt2018_2':'/IMAGES/NET/mbt2018_2',\n",
    "    'mbt2018_3':'/IMAGES/NET/mbt2018_3',\n",
    "    'mbt2018_4':'/IMAGES/NET/mbt2018_4',\n",
    "    'mbt2018_5':'/IMAGES/NET/mbt2018_5',\n",
    "    'mbt2018_mean_1':'/IMAGES/NET/mbt2018_mean_1',\n",
    "    'mbt2018_mean_2':'/IMAGES/NET/mbt2018_mean_2',\n",
    "    'mbt2018_mean_3':'/IMAGES/NET/mbt2018_mean_3',\n",
    "    'mbt2018_mean_4':'/IMAGES/NET/mbt2018_mean_4',\n",
    "    'mbt2018_mean_5':'/IMAGES/NET/mbt2018_mean_5',\n",
    "    'cheng2020_attn_1':'/IMAGES/NET/cheng2020_attn_1',\n",
    "    'cheng2020_attn_2':'/IMAGES/NET/cheng2020_attn_2',\n",
    "    'cheng2020_attn_3':'/IMAGES/NET/cheng2020_attn_3',\n",
    "    'cheng2020_attn_4':'/IMAGES/NET/cheng2020_attn_4',\n",
    "    'cheng2020_attn_5':'/IMAGES/NET/cheng2020_attn_5',\n",
    "    'cheng2020-anchor_1':'/IMAGES/NET/cheng2020-anchor_1',\n",
    "    'cheng2020-anchor_2':'/IMAGES/NET/cheng2020-anchor_2',\n",
    "    'cheng2020-anchor_3':'/IMAGES/NET/cheng2020-anchor_3',\n",
    "    'cheng2020-anchor_4':'/IMAGES/NET/cheng2020-anchor_4',\n",
    "    'cheng2020-anchor_5':'/IMAGES/NET/cheng2020-anchor_5' \n",
    "}"
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T00:02:02.927580900Z",
     "start_time": "2023-10-24T00:02:02.910507600Z"
    }
   },
   "id": "6fa5a4148e4c1b16"
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Computing metrics"
   ],
   "metadata": {
    "collapsed": false
   },
   "id": "13d1d114ef188813"
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Evaluating JPEG with dataset: C:\\Users\\filip\\DataspellProjects\\ImageCompressionAI\\IMAGES\\JPEG_IMAGES\n",
      "22.545904178905268 0.7591419219970703 0.6152011752128601 0.7280080318450928\n",
      "23.753293333180103 0.658022403717041 0.6107895970344543 0.6072699427604675\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m                         Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[3], line 18\u001B[0m\n\u001B[0;32m     16\u001B[0m mssim \u001B[38;5;241m=\u001B[39m ms_ssim(reference, compressed, data_range\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m1\u001B[39m, size_average\u001B[38;5;241m=\u001B[39m\u001B[38;5;28;01mFalse\u001B[39;00m)\n\u001B[0;32m     17\u001B[0m d1 \u001B[38;5;241m=\u001B[39m loss_fn_alex(transforms\u001B[38;5;241m.\u001B[39mNormalize(mean\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m0.5\u001B[39m, \u001B[38;5;241m0.5\u001B[39m, \u001B[38;5;241m0.5\u001B[39m), std\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m0.5\u001B[39m, \u001B[38;5;241m0.5\u001B[39m, \u001B[38;5;241m0.5\u001B[39m))(reference),transforms\u001B[38;5;241m.\u001B[39mNormalize(mean\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m0.5\u001B[39m, \u001B[38;5;241m0.5\u001B[39m, \u001B[38;5;241m0.5\u001B[39m), std\u001B[38;5;241m=\u001B[39m(\u001B[38;5;241m0.5\u001B[39m, \u001B[38;5;241m0.5\u001B[39m, \u001B[38;5;241m0.5\u001B[39m))(compressed))\n\u001B[1;32m---> 18\u001B[0m d2 \u001B[38;5;241m=\u001B[39m \u001B[43mloss_fn_vgg\u001B[49m\u001B[43m(\u001B[49m\u001B[43mtransforms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mNormalize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmean\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.5\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstd\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.5\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mreference\u001B[49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43mtransforms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mNormalize\u001B[49m\u001B[43m(\u001B[49m\u001B[43mmean\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.5\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[43mstd\u001B[49m\u001B[38;5;241;43m=\u001B[39;49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m0.5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.5\u001B[39;49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m0.5\u001B[39;49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\u001B[43m(\u001B[49m\u001B[43mcompressed\u001B[49m\u001B[43m)\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m     19\u001B[0m \u001B[38;5;28mprint\u001B[39m(\u001B[38;5;28mstr\u001B[39m(psnr) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(mssim\u001B[38;5;241m.\u001B[39mitem()) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(d1[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mitem()) \u001B[38;5;241m+\u001B[39m \u001B[38;5;124m'\u001B[39m\u001B[38;5;124m \u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;241m+\u001B[39m \u001B[38;5;28mstr\u001B[39m(d2[\u001B[38;5;241m0\u001B[39m]\u001B[38;5;241m.\u001B[39mitem()))\n",
      "File \u001B[1;32m~\\.conda\\envs\\imageCompressionAI\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\imageCompressionAI\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\imageCompressionAI\\lib\\site-packages\\lpips\\lpips.py:118\u001B[0m, in \u001B[0;36mLPIPS.forward\u001B[1;34m(self, in0, in1, retPerLayer, normalize)\u001B[0m\n\u001B[0;32m    115\u001B[0m     in1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;241m2\u001B[39m \u001B[38;5;241m*\u001B[39m in1  \u001B[38;5;241m-\u001B[39m \u001B[38;5;241m1\u001B[39m\n\u001B[0;32m    117\u001B[0m \u001B[38;5;66;03m# v0.0 - original release had a bug, where input was not scaled\u001B[39;00m\n\u001B[1;32m--> 118\u001B[0m in0_input, in1_input \u001B[38;5;241m=\u001B[39m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscaling_layer(in0), \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mscaling_layer\u001B[49m\u001B[43m(\u001B[49m\u001B[43min1\u001B[49m\u001B[43m)\u001B[49m) \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mversion\u001B[38;5;241m==\u001B[39m\u001B[38;5;124m'\u001B[39m\u001B[38;5;124m0.1\u001B[39m\u001B[38;5;124m'\u001B[39m \u001B[38;5;28;01melse\u001B[39;00m (in0, in1)\n\u001B[0;32m    119\u001B[0m outs0, outs1 \u001B[38;5;241m=\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnet\u001B[38;5;241m.\u001B[39mforward(in0_input), \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mnet\u001B[38;5;241m.\u001B[39mforward(in1_input)\n\u001B[0;32m    120\u001B[0m feats0, feats1, diffs \u001B[38;5;241m=\u001B[39m {}, {}, {}\n",
      "File \u001B[1;32m~\\.conda\\envs\\imageCompressionAI\\lib\\site-packages\\torch\\nn\\modules\\module.py:1518\u001B[0m, in \u001B[0;36mModule._wrapped_call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1516\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_compiled_call_impl(\u001B[38;5;241m*\u001B[39margs, \u001B[38;5;241m*\u001B[39m\u001B[38;5;241m*\u001B[39mkwargs)  \u001B[38;5;66;03m# type: ignore[misc]\u001B[39;00m\n\u001B[0;32m   1517\u001B[0m \u001B[38;5;28;01melse\u001B[39;00m:\n\u001B[1;32m-> 1518\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43m_call_impl\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n",
      "File \u001B[1;32m~\\.conda\\envs\\imageCompressionAI\\lib\\site-packages\\torch\\nn\\modules\\module.py:1527\u001B[0m, in \u001B[0;36mModule._call_impl\u001B[1;34m(self, *args, **kwargs)\u001B[0m\n\u001B[0;32m   1522\u001B[0m \u001B[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001B[39;00m\n\u001B[0;32m   1523\u001B[0m \u001B[38;5;66;03m# this function, and just call forward.\u001B[39;00m\n\u001B[0;32m   1524\u001B[0m \u001B[38;5;28;01mif\u001B[39;00m \u001B[38;5;129;01mnot\u001B[39;00m (\u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39m_forward_pre_hooks\n\u001B[0;32m   1525\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_backward_pre_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_backward_hooks\n\u001B[0;32m   1526\u001B[0m         \u001B[38;5;129;01mor\u001B[39;00m _global_forward_hooks \u001B[38;5;129;01mor\u001B[39;00m _global_forward_pre_hooks):\n\u001B[1;32m-> 1527\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m \u001B[43mforward_call\u001B[49m\u001B[43m(\u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43margs\u001B[49m\u001B[43m,\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[38;5;241;43m*\u001B[39;49m\u001B[43mkwargs\u001B[49m\u001B[43m)\u001B[49m\n\u001B[0;32m   1529\u001B[0m \u001B[38;5;28;01mtry\u001B[39;00m:\n\u001B[0;32m   1530\u001B[0m     result \u001B[38;5;241m=\u001B[39m \u001B[38;5;28;01mNone\u001B[39;00m\n",
      "File \u001B[1;32m~\\.conda\\envs\\imageCompressionAI\\lib\\site-packages\\lpips\\lpips.py:154\u001B[0m, in \u001B[0;36mScalingLayer.forward\u001B[1;34m(self, inp)\u001B[0m\n\u001B[0;32m    153\u001B[0m \u001B[38;5;28;01mdef\u001B[39;00m \u001B[38;5;21mforward\u001B[39m(\u001B[38;5;28mself\u001B[39m, inp):\n\u001B[1;32m--> 154\u001B[0m     \u001B[38;5;28;01mreturn\u001B[39;00m (\u001B[43minp\u001B[49m\u001B[43m \u001B[49m\u001B[38;5;241;43m-\u001B[39;49m\u001B[43m \u001B[49m\u001B[38;5;28;43mself\u001B[39;49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mshift\u001B[49m) \u001B[38;5;241m/\u001B[39m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mscale\n",
      "\u001B[1;31mKeyboardInterrupt\u001B[0m: "
     ]
    }
   ],
   "source": [
    "for name, path in datasets.items():\n",
    "    psnr_list=[]\n",
    "    mssim_list=[]\n",
    "    lpips_list=[]\n",
    "    count = 0\n",
    "    compressed_path = str(current_path)+path\n",
    "    print('Evaluating '+name+' with dataset: '+str(compressed_path))\n",
    "    for file in glob.glob(str(compressed_path)+'/*.png'):\n",
    "        reference_image = Image.open(reference_path+'/'+Path(file).stem+'.png')\n",
    "        reference = transforms.ToTensor()(reference_image).unsqueeze(0).to(device)\n",
    "        compressed_image = Image.open(file)\n",
    "        compressed = transforms.ToTensor()(compressed_image).unsqueeze(0).to(device)\n",
    "        psnr = metrics.peak_signal_noise_ratio(numpy.array(reference_image),numpy.array(compressed_image),data_range=255)\n",
    "        reference_image.close()\n",
    "        compressed_image.close()\n",
    "        mssim = ms_ssim(reference, compressed, data_range=1, size_average=False)\n",
    "        d1 = loss_fn_alex(transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))(reference),transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))(compressed))\n",
    "        d2 = loss_fn_vgg(transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))(reference),transforms.Normalize(mean=(0.5, 0.5, 0.5), std=(0.5, 0.5, 0.5))(compressed))\n",
    "        print(str(psnr) + ' ' + str(mssim.item()) + ' ' + str(d1[0].item()) + ' ' + str(d2[0].item()))\n",
    " \n",
    "    "
   ],
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2023-10-24T00:04:01.090085300Z",
     "start_time": "2023-10-24T00:02:06.363857300Z"
    }
   },
   "id": "e9a1ed8516e8314a"
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
